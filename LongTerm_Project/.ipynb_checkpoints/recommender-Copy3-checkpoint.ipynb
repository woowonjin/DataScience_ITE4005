{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train_file = sys.argv[1]\n",
    "# test_file = sys.argv[2]\n",
    "train_file = \"u1.base\"\n",
    "test_file = \"u1.test\"\n",
    "\n",
    "k = 50  # number of iteration\n",
    "alpha = 0.25  # learning rate\n",
    "_lambda = 0.1  # parameter for regularizer\n",
    "patience = 5  # number of patience that not improved from previous version\n",
    "attr_num = 12  # number of columns in factorized matrix\n",
    "column_names = [\"user_id\", \"item_id\", \"rating\", \"time_stamp\"]\n",
    "\n",
    "dataframe = pd.read_csv(train_file, sep=\"\\t\", names=column_names, header=None)\n",
    "testframe = pd.read_csv(test_file, sep=\"\\t\", names=column_names, header=None)\n",
    "\n",
    "dataframe = dataframe.drop([\"time_stamp\"], axis=1)\n",
    "testframe = testframe.drop([\"time_stamp\"], axis=1)\n",
    "\n",
    "last_movie = dataframe[\"item_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating\n",
      "6793       119       70       3\n",
      "12405      234      153       3\n",
      "41047      540      628       3\n",
      "11533      216      546       2\n",
      "31975      457      252       4\n",
      "...        ...      ...     ...\n",
      "63206      776      192       5\n",
      "61404      757      179       4\n",
      "17730      308       24       4\n",
      "28030      425      156       5\n",
      "15725      286       47       4\n",
      "\n",
      "[76000 rows x 3 columns]\n",
      "       user_id  item_id  rating\n",
      "23438      385       18       5\n",
      "78749      932      429       5\n",
      "43994      570      327       4\n",
      "25959      405      999       1\n",
      "20526      342     1011       3\n",
      "...        ...      ...     ...\n",
      "15858      286     1038       5\n",
      "36880      503        1       5\n",
      "7921       145      559       2\n",
      "71524      867      198       5\n",
      "44208      577       22       5\n",
      "\n",
      "[4000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(dataframe, test_size=0.05, random_state=123)\n",
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                              ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   NaN   4.0   1.0   5.0   NaN  ...   \n",
      "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n",
      "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
      "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n",
      "\n",
      "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "user_id                                                              \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[943 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "df_table = train_data.pivot(\"user_id\", \"item_id\", \"rating\")\n",
    "for i in range(1, last_movie+1):\n",
    "    if not i in df_table.columns:\n",
    "        df_table[i] = np.NaN\n",
    "df_table = df_table[[i for i in range(1, last_movie+1)]]\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385  18   1]\n",
      " [932 429   1]\n",
      " [570 327   1]\n",
      " ...\n",
      " [145 559   1]\n",
      " [867 198   1]\n",
      " [577  22   1]]\n",
      "(76000, 2)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "pre_use_mat = df_table.replace([1.0, 2.0, 3.0, 4.0, 5.0], 1.0).values\n",
    "pre_use_val = copy.deepcopy(val_data.values)\n",
    "for temp in pre_use_val:\n",
    "    temp[2] = 1\n",
    "print(pre_use_val)\n",
    "row = pre_use_mat.shape[0]\n",
    "col = pre_use_mat.shape[1]\n",
    "rated_indexes = np.argwhere(pre_use_mat == 1)\n",
    "print(rated_indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_with_bias(y, p, q, b_p, b_q, mean):\n",
    "    return ((y-mean-b_p-b_q-np.dot(p, q))**2+_lambda*np.sqrt(np.sum(np.square(p))) + _lambda*np.sqrt(np.sum(np.square(q))) + _lambda*(b_p**2) + _lambda*(b_q**2) + 0.e-10)\n",
    "\n",
    "def mf_uninteresting(index_arr, validation_set):\n",
    "    p = np.random.rand(row, attr_num)  # number of parameter : row * 3\n",
    "    q = np.random.rand(col, attr_num)  # number of parameter : col * 3\n",
    "    b_p = np.random.rand(row, 1)\n",
    "    b_q = np.random.rand(col, 1)\n",
    "    min_rmse_error = 9999999\n",
    "    best_p = None\n",
    "    best_q = None\n",
    "    best_b_p = None\n",
    "    best_b_q = None\n",
    "    not_improved_cnt = 0\n",
    "    for _ in range(k):\n",
    "        d_p = [[np.zeros(attr_num), 0] for _ in range(row)]\n",
    "        d_q = [[np.zeros(attr_num), 0] for _ in range(col)]\n",
    "        d_b_p = [[0, 0] for _ in range(row)]\n",
    "        d_b_q = [[0, 0] for _ in range(col)]\n",
    "        error = 0\n",
    "        for i, j in index_arr:\n",
    "            p_i = p[i]\n",
    "            q_j = q[j]\n",
    "            b_p_i = b_p[i][0]\n",
    "            b_q_j = b_q[j][0]\n",
    "            a = np.dot(p_i, q_j)\n",
    "            # values of derivation p\n",
    "            d_p[i][0] += _lambda*p_i - (1-b_p_i-b_q_j-1-a)*q_j\n",
    "            d_p[i][1] += 1  # cnt\n",
    "            d_q[j][0] += _lambda*q_j - (1-b_p_i-b_q_j-1-a)*p_i\n",
    "            d_q[j][1] += 1\n",
    "            d_b_p[i][0] += _lambda*b_p_i - (1-b_p_i-b_q_j-1-a)\n",
    "            d_b_p[i][1] += 1\n",
    "            d_b_q[j][0] += _lambda*b_q_j - (1-b_p_i-b_q_j-1-a)\n",
    "            d_b_q[j][1] += 1\n",
    "            error += mean_squared_error_with_bias(\n",
    "                1, p[i], q[j], b_p_i, b_q_j, 1)\n",
    "            \n",
    "        # current value - derivation_averageÂ«\n",
    "        for i in range(row):\n",
    "            if d_p[i][1] != 0:\n",
    "                p[i] -= alpha*(d_p[i][0]/d_p[i][1])\n",
    "                b_p[i][0] -= alpha*(d_b_p[i][0]/d_b_p[i][1])\n",
    "        # current value - derivation_average\n",
    "        for j in range(col):\n",
    "            if d_q[j][1] != 0:\n",
    "                q[j] -= alpha*(d_q[j][0]/d_q[j][1])\n",
    "                b_q[j][0] -= alpha*(d_b_q[j][0]/d_b_q[j][1])\n",
    "        error_ = error/len(index_arr)\n",
    "        print(\"Training_error : \", error_)\n",
    "        result_temp = np.dot(p, q.transpose()) + 1\n",
    "        result_temp += b_p\n",
    "        result_temp += b_q.transpose()\n",
    "        rmse_error = 0\n",
    "        for user, movie, rating in validation_set:\n",
    "            rmse_error += (result_temp[user-1][movie-1]-rating) ** 2\n",
    "        rmse_error = np.sqrt(rmse_error/len(validation_set))\n",
    "        print(\"Validation Error : \", rmse_error)\n",
    "        if rmse_error < min_rmse_error:\n",
    "            min_rmse_error = rmse_error\n",
    "            best_p = p\n",
    "            best_q = q\n",
    "            best_b_p = b_p\n",
    "            best_b_q = b_q\n",
    "        else:\n",
    "            not_improved_cnt += 1\n",
    "            print(f\"Did not improved from {min_rmse_error} to {rmse_error}\")\n",
    "            if not_improved_cnt >= patience:\n",
    "                print(\"Early Stopped!!\")\n",
    "                return best_p, best_q, best_b_p, best_b_q\n",
    "    return best_p, best_q, best_b_p, best_b_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_error :  16.92184425664936\n",
      "Validation Error :  1.0849807538867935\n",
      "Training_error :  1.4986039381566432\n",
      "Validation Error :  0.570752452773726\n",
      "Training_error :  0.5370482361888429\n",
      "Validation Error :  0.35120043528392014\n",
      "Training_error :  0.2996280379973063\n",
      "Validation Error :  0.25885960546466696\n",
      "Training_error :  0.22798081083379806\n",
      "Validation Error :  0.21551064328595246\n",
      "Training_error :  0.19836339133902772\n",
      "Validation Error :  0.1901662042399831\n",
      "Training_error :  0.18143672537908836\n",
      "Validation Error :  0.17227211182046595\n",
      "Training_error :  0.16941923130138256\n",
      "Validation Error :  0.15819218417501812\n",
      "Training_error :  0.15984468059061752\n",
      "Validation Error :  0.1464605088364247\n",
      "Training_error :  0.15174030767201732\n",
      "Validation Error :  0.13635559675379663\n",
      "Training_error :  0.14463801505170246\n",
      "Validation Error :  0.1274635153439676\n",
      "Training_error :  0.13827723026213892\n",
      "Validation Error :  0.11952323277792119\n",
      "Training_error :  0.13249735584762473\n",
      "Validation Error :  0.1123597737281643\n",
      "Training_error :  0.12719152163956401\n",
      "Validation Error :  0.10585009614652435\n",
      "Training_error :  0.12228405267389685\n",
      "Validation Error :  0.09990386648744959\n",
      "Training_error :  0.11771855710142706\n",
      "Validation Error :  0.09445206797573068\n",
      "Training_error :  0.11345125488680388\n",
      "Validation Error :  0.08944005299075272\n",
      "Training_error :  0.10944705582455888\n",
      "Validation Error :  0.08482320831735543\n",
      "Training_error :  0.10567714342840129\n",
      "Validation Error :  0.08056418584443303\n",
      "Training_error :  0.10211741483982778\n",
      "Validation Error :  0.07663108481062972\n",
      "Training_error :  0.0987474258036375\n",
      "Validation Error :  0.07299622145337074\n",
      "Training_error :  0.09554964565693391\n",
      "Validation Error :  0.06963526813504728\n",
      "Training_error :  0.09250891068956228\n",
      "Validation Error :  0.06652663025293191\n",
      "Training_error :  0.08961200988587653\n",
      "Validation Error :  0.06365098037949182\n",
      "Training_error :  0.08684736263633842\n",
      "Validation Error :  0.0609908996055968\n",
      "Training_error :  0.08420476271737429\n",
      "Validation Error :  0.05853059443406015\n",
      "Training_error :  0.08167517154932233\n",
      "Validation Error :  0.05625566875020482\n",
      "Training_error :  0.07925054907201062\n",
      "Validation Error :  0.05415293728569497\n",
      "Training_error :  0.07692371395416624\n",
      "Validation Error :  0.05221027130110381\n",
      "Training_error :  0.07468822706999347\n",
      "Validation Error :  0.050416469952050395\n",
      "Training_error :  0.07253829368408353\n",
      "Validation Error :  0.04876115257502989\n",
      "Training_error :  0.07046868084504335\n",
      "Validation Error :  0.047234668294478754\n",
      "Training_error :  0.06847464725454847\n",
      "Validation Error :  0.04582802013338783\n",
      "Training_error :  0.06655188344673624\n",
      "Validation Error :  0.044532801343568185\n",
      "Training_error :  0.064696460543375\n",
      "Validation Error :  0.043341142046104335\n",
      "Training_error :  0.06290478618193586\n",
      "Validation Error :  0.04224566454465837\n",
      "Training_error :  0.06117356647309566\n",
      "Validation Error :  0.04123944588196194\n",
      "Training_error :  0.05949977304924742\n",
      "Validation Error :  0.040315986378276165\n",
      "Training_error :  0.057880614429485854\n",
      "Validation Error :  0.039469183036423994\n",
      "Training_error :  0.05631351105834154\n",
      "Validation Error :  0.03869330683153738\n",
      "Training_error :  0.054796073482529725\n",
      "Validation Error :  0.03798298303073835\n",
      "Training_error :  0.05332608321715982\n",
      "Validation Error :  0.037333173811040836\n",
      "Training_error :  0.051901475924388076\n",
      "Validation Error :  0.03673916256297318\n",
      "Training_error :  0.0505203265864266\n",
      "Validation Error :  0.036196539381484094\n",
      "Training_error :  0.04918083640359421\n",
      "Validation Error :  0.03570118735258964\n",
      "Training_error :  0.04788132118865805\n",
      "Validation Error :  0.03524926934180648\n",
      "Training_error :  0.04662020106249088\n",
      "Validation Error :  0.03483721507685424\n",
      "Training_error :  0.04539599128443081\n",
      "Validation Error :  0.03446170839113351\n",
      "Training_error :  0.04420729407448289\n",
      "Validation Error :  0.03411967455551967\n",
      "Training_error :  0.04305279130457018\n",
      "Validation Error :  0.033808267674175475\n"
     ]
    }
   ],
   "source": [
    "uninteresting_p, uninteresting_q, uninteresting_b_p, uninteresting_b_q = mf_uninteresting(rated_indexes, pre_use_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00110966 0.98399605 1.00605248 ... 1.02003713 1.03909422 1.03100693]\n",
      " [0.99014735 1.0052759  1.00627177 ... 1.01915378 1.01863363 1.02316111]\n",
      " [0.98663037 1.0000644  0.99608784 ... 1.039364   1.00702774 1.00712479]\n",
      " ...\n",
      " [1.02379402 1.01276423 0.99151916 ... 1.0187864  0.99049357 0.99173722]\n",
      " [1.0060016  1.00709032 0.97670242 ... 1.01960336 1.05018873 1.00219333]\n",
      " [0.98371384 1.00001488 1.0059611  ... 1.05820256 0.99990524 1.04246289]]\n",
      "(101, 2)\n"
     ]
    }
   ],
   "source": [
    "pre_use_mat_result = np.dot(uninteresting_p, uninteresting_q.transpose()) + 1\n",
    "pre_use_mat_result += uninteresting_b_p\n",
    "pre_use_mat_result += uninteresting_b_q.transpose() \n",
    "print(pre_use_mat_result)\n",
    "uninteresting_rating_index = np.argwhere(pre_use_mat_result < 0.8)\n",
    "print(uninteresting_rating_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rating_mat = df_table.fillna(-1).values\n",
    "for index in uninteresting_rating_index:\n",
    "    original_rating_mat[index[0]][index[1]] = 1\n",
    "result_rated_indexes = np.argwhere(original_rating_mat >= 0)\n",
    "rating_sum = 0\n",
    "cnt = 0\n",
    "for index in result_rated_indexes:\n",
    "    rating_sum += original_rating_mat[index[0]][index[1]]\n",
    "    cnt += 1\n",
    "rating_mean = rating_sum / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_with_bias(y, p, q, b_p, b_q, mean):\n",
    "    return ((y-mean-b_p-b_q-np.dot(p, q))**2+_lambda*np.sqrt(np.sum(np.square(p))) + _lambda*np.sqrt(np.sum(np.square(q))) + _lambda*(b_p**2) + _lambda*(b_q**2) + 0.e-10)\n",
    "\n",
    "\n",
    "def mf_training(index_arr, data_arr, validation_set, mean):\n",
    "    p = np.random.rand(row, attr_num)  # number of parameter : row * attr_num\n",
    "    q = np.random.rand(col, attr_num)  # number of parameter : col * attr_num\n",
    "    b_p = np.random.rand(row, 1)\n",
    "    b_q = np.random.rand(col, 1)\n",
    "    min_rmse_error = 9999999\n",
    "    best_p = None\n",
    "    best_q = None\n",
    "    best_b_p = None\n",
    "    best_b_q = None\n",
    "    not_improved_cnt = 0\n",
    "    for _ in range(k):\n",
    "        d_p = [[np.zeros(attr_num), 0] for _ in range(row)]\n",
    "        d_q = [[np.zeros(attr_num), 0] for _ in range(col)]\n",
    "        d_b_p = [[0, 0] for _ in range(row)]\n",
    "        d_b_q = [[0, 0] for _ in range(col)]\n",
    "        acc_error = 0\n",
    "        rmse_error = 0\n",
    "        for i, j in index_arr:\n",
    "            p_i = p[i]\n",
    "            q_j = q[j]\n",
    "            b_p_i = b_p[i][0]\n",
    "            b_q_j = b_q[j][0]\n",
    "            a = np.dot(p_i, q_j)\n",
    "            # values of derivation p\n",
    "            d_p[i][0] += _lambda*p_i - (data_arr[i][j]-b_p_i-b_q_j-mean-a)*q_j\n",
    "            d_p[i][1] += 1  # cnt\n",
    "            d_q[j][0] += _lambda*q_j - (data_arr[i][j]-b_p_i-b_q_j-mean-a)*p_i\n",
    "            d_q[j][1] += 1\n",
    "            d_b_p[i][0] += _lambda*b_p_i - (data_arr[i][j]-b_p_i-b_q_j-mean-a)\n",
    "            d_b_p[i][1] += 1\n",
    "            d_b_q[j][0] += _lambda*b_q_j - (data_arr[i][j]-b_p_i-b_q_j-mean-a)\n",
    "            d_b_q[j][1] += 1\n",
    "            acc_error += mean_squared_error_with_bias(\n",
    "                data_arr[i][j], p[i], q[j], b_p_i, b_q_j, mean)\n",
    "\n",
    "\n",
    "        # current value - derivation_averageÂ«\n",
    "        for i in range(row):\n",
    "            if d_p[i][1] != 0:\n",
    "                p[i] -= alpha*(d_p[i][0]/d_p[i][1])\n",
    "                b_p[i][0] -= alpha*(d_b_p[i][0]/d_b_p[i][1])\n",
    "        # current value - derivation_average\n",
    "        for j in range(col):\n",
    "            if d_q[j][1] != 0:\n",
    "                q[j] -= alpha*(d_q[j][0]/d_q[j][1])\n",
    "                b_q[j][0] -= alpha*(d_b_q[j][0]/d_b_q[j][1])\n",
    "        \n",
    "        acc_error_ = acc_error/len(index_arr)\n",
    "        print(\"Training Error : \", acc_error_)\n",
    "        # for validation\n",
    "        result_temp = np.dot(p, q.transpose())+mean\n",
    "        result_temp += b_p\n",
    "        result_temp += b_q.transpose()\n",
    "        for user, movie, rating in validation_set:\n",
    "            rmse_error += (result_temp[user-1][movie-1]-rating) ** 2\n",
    "        rmse_error = np.sqrt(rmse_error/len(validation_set))\n",
    "        print(\"Validation Error : \", rmse_error)\n",
    "        if rmse_error < min_rmse_error:\n",
    "            min_rmse_error = rmse_error\n",
    "            best_p = p\n",
    "            best_q = q\n",
    "            best_b_p = b_p\n",
    "            best_b_q = b_q\n",
    "        else:\n",
    "            not_improved_cnt += 1\n",
    "            print(f\"Did not improved from {min_rmse_error} to {rmse_error}\")\n",
    "            if not_improved_cnt >= patience:\n",
    "                print(\"Early Stopped!!\")\n",
    "                return best_p, best_q, best_b_p, best_b_q\n",
    "    return best_p, best_q, best_b_p, best_b_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385  18   5]\n",
      " [932 429   5]\n",
      " [570 327   4]\n",
      " ...\n",
      " [145 559   2]\n",
      " [867 198   5]\n",
      " [577  22   5]]\n",
      "Training Error :  18.532965275232343\n",
      "Validation Error :  1.5459544340060485\n",
      "Training Error :  2.6845043136419493\n",
      "Validation Error :  1.1546798088753594\n",
      "Training Error :  1.5212368240442504\n",
      "Validation Error :  1.0273268713263064\n",
      "Training Error :  1.2043582157512847\n",
      "Validation Error :  0.9834508068680977\n",
      "Training Error :  1.0956617649453324\n",
      "Validation Error :  0.9652222115256803\n",
      "Training Error :  1.0464404229864788\n",
      "Validation Error :  0.9558750296115038\n",
      "Training Error :  1.0180243494424803\n",
      "Validation Error :  0.9502365371881488\n",
      "Training Error :  0.998714680718501\n",
      "Validation Error :  0.9464462390222967\n",
      "Training Error :  0.9842326157950738\n",
      "Validation Error :  0.9437064549676044\n",
      "Training Error :  0.9726865986171702\n",
      "Validation Error :  0.9416207882621624\n",
      "Training Error :  0.9631021826346718\n",
      "Validation Error :  0.9399702103658613\n",
      "Training Error :  0.9549186099016037\n",
      "Validation Error :  0.9386242161890178\n",
      "Training Error :  0.9477860143329351\n",
      "Validation Error :  0.937500393080425\n",
      "Training Error :  0.9414719312711987\n",
      "Validation Error :  0.9365441031754361\n",
      "Training Error :  0.9358137457057454\n",
      "Validation Error :  0.9357175545279254\n",
      "Training Error :  0.9306927375455314\n",
      "Validation Error :  0.9349936232907299\n",
      "Training Error :  0.9260191200506739\n",
      "Validation Error :  0.9343522161767149\n",
      "Training Error :  0.9217230050609998\n",
      "Validation Error :  0.9337780476864744\n",
      "Training Error :  0.9177487125286913\n",
      "Validation Error :  0.93325923263126\n",
      "Training Error :  0.9140510437371021\n",
      "Validation Error :  0.9327863635938163\n",
      "Training Error :  0.9105927509515617\n",
      "Validation Error :  0.9323518859197827\n",
      "Training Error :  0.9073427620941005\n",
      "Validation Error :  0.9319496610001459\n",
      "Training Error :  0.9042748980381949\n",
      "Validation Error :  0.9315746524326987\n",
      "Training Error :  0.9013669215122827\n",
      "Validation Error :  0.9312226948118559\n",
      "Training Error :  0.8985998157479845\n",
      "Validation Error :  0.9308903196854017\n",
      "Training Error :  0.8959572265287723\n",
      "Validation Error :  0.9305746221212995\n",
      "Training Error :  0.8934250232364861\n",
      "Validation Error :  0.9302731568225293\n",
      "Training Error :  0.89099094842309\n",
      "Validation Error :  0.9299838562046655\n",
      "Training Error :  0.8886443345045191\n",
      "Validation Error :  0.9297049651058844\n",
      "Training Error :  0.8863758722198454\n",
      "Validation Error :  0.9294349882976584\n",
      "Training Error :  0.8841774196162204\n",
      "Validation Error :  0.9291726479834216\n",
      "Training Error :  0.8820418431811925\n",
      "Validation Error :  0.9289168491810386\n",
      "Training Error :  0.879962884767253\n",
      "Validation Error :  0.928666651387457\n",
      "Training Error :  0.8779350494130715\n",
      "Validation Error :  0.9284212452877653\n",
      "Training Error :  0.8759535102341481\n",
      "Validation Error :  0.9281799335388343\n",
      "Training Error :  0.8740140273536986\n",
      "Validation Error :  0.9279421148589015\n",
      "Training Error :  0.8721128784487678\n",
      "Validation Error :  0.9277072708080146\n",
      "Training Error :  0.8702467989513755\n",
      "Validation Error :  0.9274749547633393\n",
      "Training Error :  0.868412930308845\n",
      "Validation Error :  0.9272447826872264\n",
      "Training Error :  0.866608774993881\n",
      "Validation Error :  0.92701642536089\n",
      "Training Error :  0.8648321571857647\n",
      "Validation Error :  0.9267896018170709\n",
      "Training Error :  0.8630811882298153\n",
      "Validation Error :  0.9265640737544479\n",
      "Training Error :  0.8613542361342875\n",
      "Validation Error :  0.9263396407569386\n",
      "Training Error :  0.8596498984881221\n",
      "Validation Error :  0.9261161361743281\n",
      "Training Error :  0.8579669782867339\n",
      "Validation Error :  0.9258934235479336\n",
      "Training Error :  0.8563044622383783\n",
      "Validation Error :  0.9256713934874549\n",
      "Training Error :  0.8546615011953794\n",
      "Validation Error :  0.9254499609233339\n",
      "Training Error :  0.853037392414698\n",
      "Validation Error :  0.9252290626736729\n",
      "Training Error :  0.8514315634023297\n",
      "Validation Error :  0.9250086552766672\n",
      "Training Error :  0.8498435571388416\n",
      "Validation Error :  0.9247887130486425\n"
     ]
    }
   ],
   "source": [
    "valid_set = val_data.values\n",
    "print(valid_set)\n",
    "p, q, b_p, b_q = mf_training(result_rated_indexes, original_rating_mat, valid_set, rating_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.93362117 3.19661477 3.28158924 ... 2.55695569 3.5519061  3.26420007]\n",
      " [4.01649156 3.50438831 3.02579217 ... 3.10346694 3.6256568  3.57582077]\n",
      " [3.59330852 3.13171318 2.41290662 ... 2.07223211 3.31882997 2.77411857]\n",
      " ...\n",
      " [4.15213804 3.50593148 3.32397829 ... 2.98852406 3.86747191 3.50326272]\n",
      " [4.33564474 3.72929896 3.47706238 ... 3.29570767 4.03193773 3.82024666]\n",
      " [3.78831102 3.28384381 2.75445542 ... 2.98061059 3.44293146 3.32246295]]\n"
     ]
    }
   ],
   "source": [
    "recommend_result = np.dot(p, q.transpose()) + rating_mean\n",
    "recommend_result += b_p\n",
    "recommend_result += b_q.transpose() \n",
    "recommend_result = np.where(recommend_result < 1.0, 1, recommend_result)\n",
    "recommend_result = np.where(recommend_result > 5.0, 5, recommend_result)\n",
    "print(recommend_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532818962833747\n"
     ]
    }
   ],
   "source": [
    "rmse = 0\n",
    "cnt = 0\n",
    "for_write = []\n",
    "for user, movie, rating in testframe.values:\n",
    "    if user > row or movie > col:\n",
    "            for_write.append([user, movie, 3])\n",
    "            rmse += (rating-3)**2\n",
    "    else:\n",
    "        for_write.append([user, movie, recommend_result[user-1][movie-1]])\n",
    "        rmse += (rating-recommend_result[user-1][movie-1])**2\n",
    "rmse = np.sqrt(rmse/testframe.shape[0])\n",
    "print(rmse)\n",
    "df_write = pd.DataFrame(for_write)\n",
    "df_write.to_csv(train_file+\"_prediction.txt\", sep=\"\\t\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
